#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage{multirow}
\usepackage{amsmath}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing double
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Title
\end_layout

\begin_layout Author
Author
\end_layout

\begin_layout Date
date
\end_layout

\begin_layout Section
Feature Extration
\end_layout

\begin_layout Standard
lda
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\begin_inset Graphics
	filename images/lda.png
	lyxscale 40
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
LDA for tongue protruding down
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\begin_inset Graphics
	filename images/ldas.png
	lyxscale 40
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
LDA for 6 classes(first row: close, down, left; second row: open, right,up)
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Data Pre-processing and Augmentation
\end_layout

\begin_layout Standard
Resize & shuffle, normalization 
\end_layout

\begin_layout Standard
Parameter setting, Random brightness/saturation/contrast, Random lighting,
\end_layout

\begin_layout Standard
Since the neural network only accept uniform input size, we resized and
 cropped all the image to 45x37x3 and take the central area of them.
 We also normalized the training data respecting to the mean the variance
 of the whole training set.
\end_layout

\begin_layout Standard
It's a common method to reduce overfitting by using label-preserving transformat
ions.
 In our implementation, the transformed images are generated on the CPU
 while the training is taking place on the GPU.
 Our data augmentation method altered the intensities of the RGB channels
 in training images.
 More specifically, we performed PCA on the set of RGB pixel values throughout
 the training set.
 To each training image, we add multiple of the found pricipal components,
 with magnitudes proportional to the corresponding eigenvalues times a random
 viriable drawn from a Gaussian with mean zero and standard deviation 0.1.
 Therefore to each RGB image pixel 
\begin_inset Formula $I{}_{xy}=[I_{xy}^{R},I_{xy}^{G},I_{xy}^{B}]^{T}$
\end_inset

 we add the following quantity:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{equation*}
\end_layout

\begin_layout Plain Layout

[p_1, p_2, p_3][
\backslash
alpha_1
\backslash
lambda_1, 
\backslash
alpha_2
\backslash
lambda_2, 
\backslash
alpha_3
\backslash
lambda_3]
\end_layout

\begin_layout Plain Layout


\backslash
end{equation*}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset ERT
status open

\begin_layout Plain Layout

$p_i$
\end_layout

\end_inset

 and 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
lambda_i$
\end_layout

\end_inset

 are 
\begin_inset ERT
status open

\begin_layout Plain Layout

$i$
\end_layout

\end_inset

th eigenvector and eigenvalue of the 3x3 convariance matrix of RGB pixel
 values, respectively, and 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
alpha_i$
\end_layout

\end_inset

 is the random variable.
 (# from ImageNet)
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\begin_inset Graphics
	filename images/imageenhancement.png
	lyxscale 20
	scale 20

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Randomly enhanced images
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\begin_inset Graphics
	filename images/pca.png
	lyxscale 60
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Principle components extraction for 6 classes
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Model
\end_layout

\begin_layout Standard
cnn introduction, model structure
\end_layout

\begin_layout Standard
There are several kinds of layers in our CNN model:
\end_layout

\begin_layout Standard
Input layer [45x37x3] will hold the raw pixel values of the image, in this
 case an image of width 45, height 37, and with three color channels R,G,B;
\end_layout

\begin_layout Standard
Convolutional layer will compute the output of neurons that are connected
 to local regions in the input, each computing a dot product between their
 weights and the region they are connected to in the input volume.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\begin_inset Graphics
	filename images/convlayer.png
	lyxscale 50
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Convolutional layer(image from http://cs231n.github.io/)
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
ReLU layer will apply an elementwise activation function with the threshold
 of zero;
\end_layout

\begin_layout Standard
Maxpooling layer will perform a downsampling operation along the spatial
 dimensions (width, height);
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\begin_inset Graphics
	filename images/maxpool.png
	lyxscale 40
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Maxpooling layer(image from http://cs231n.github.io/)
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Fully connected layer will compute the class scores, resulting in volume
 of size [1x1x6], where each of the 6 numbers correspond to a class score,
 such as among the 6 categories of dataset.
 Each neuron in this layer will be connected to all the numbers in the previous
 volume;
\end_layout

\begin_layout Standard
Here is the structure of our CNN model:
\end_layout

\begin_layout Standard
Input(45 x 37 x 3) ==> Convolution(3 -> 64, 12 x 4) ==> Maxpool(3 x 3, 2,
 2, 1, 1) ==> ReLU ==> Convolution(64 -> 64, 3 x 3, 1, 1, 1, 1) 
\end_layout

\begin_layout Standard
==> ReLU ==> Convolution(64 -> 64, 3 x 3, 1, 1, 1, 1) ==>Maxpool ==> ReLU
 ==> Convolution(64 -> 256, 9 x 9) ==> Dropout(0.5) ==> ReLU ==> Reshape(256)
 
\end_layout

\begin_layout Standard
==> Linear(256 -> 6) ==>Softmax
\end_layout

\begin_layout Section
Details of training
\end_layout

\begin_layout Standard
To get an estimation of the accuracy, we implemented 10-fold cross validation.
 We randomly separate the dataset into 10 subsets and trained 10 models
 on each subset one by one.
 We trained the models with a batch size of 128 examples, momentum of 0.9,
 weight decay of 0.00005, learning rate of 0.001 and learning rate decay of
 
\begin_inset Formula $10{}^{-7}$
\end_inset

.
 We found small amount of weight decay was important for the model to learn.
 The results appear good enough after about 400 epochs and it took 4-5 hours.
 After training, we test the 10 models on the test set simutaneouly to get
 the mean and standard deviation of the accuracy.
 
\end_layout

\begin_layout Standard
After that, we trained our final model on the whole dataset.
 We use 8 CPU threads to prepare the minibatches.
 We use data augmentation with horizontal flipping and random brightness/saturat
ion/contrast adjustment.
 For each image, data augmentation could generate up to (# ???) different
 situations.
 We use stochastic gradient descent on NVidia TITAN X GPU to train the entire
 network for about (# ???) hours.
 (# more details here...)
\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Standard
Without meta-learning, the testing accurary was less than 90% while the
 training accurary approaching 100%.
 By using meta-learning, we achieved the average accuracy of 99.4% with standard
 deviation less than 0.3% for the 10-fold cross validation models.
 We found that meta-learning procedure really helped reduce overfitting
 problem.
 However, the result was extremly biased since we were only training on
 4 training subjects in six lighting conditions.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\begin_inset Graphics
	filename images/total_accuracy_without_metalearning.png
	lyxscale 25
	scale 20

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
total accuracy without meta learning
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\begin_inset Graphics
	filename images/total_accuracy_with_metalearning1.png
	lyxscale 20
	scale 20

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
total accuracy with meta learning
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\begin_inset Graphics
	filename images/total_accuracy_with_metalearning2.png
	lyxscale 40
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
overly optimistic prediction
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[]
\end_layout

\begin_layout Plain Layout


\backslash
caption{Confusion matrix over the blind test dataset}
\end_layout

\begin_layout Plain Layout


\backslash
centering 
\end_layout

\begin_layout Plain Layout


\backslash
label{my-label} 
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{cccccccc}  
\end_layout

\begin_layout Plain Layout

& 
\backslash
multicolumn{7}{c}{
\backslash
textbf{Actual}} 
\backslash

\backslash
 
\backslash
cline{2-8}  
\end_layout

\begin_layout Plain Layout


\backslash
multicolumn{1}{c|}{
\backslash
multirow{7}{*}{
\backslash
rotatebox[origin=c]{90}{
\backslash
textbf{Predicted}}}} & 
\backslash
multicolumn{1}{c|}{} & 
\backslash
multicolumn{1}{c|}{C} & 
\backslash
multicolumn{1}{c|}{O} & 
\backslash
multicolumn{1}{c|}{U} & 
\backslash
multicolumn{1}{c|}{D} & 
\backslash
multicolumn{1}{c|}{R} & 
\backslash
multicolumn{1}{c|}{L} 
\backslash

\backslash
 
\backslash
cline{2-8} 
\end_layout

\begin_layout Plain Layout


\backslash
multicolumn{1}{c|}{} & 
\backslash
multicolumn{1}{c|}{C} & 
\backslash
multicolumn{1}{c|}{3337} & 
\backslash
multicolumn{1}{c|}{0} & 
\backslash
multicolumn{1}{c|}{23} & 
\backslash
multicolumn{1}{c|}{7} & 
\backslash
multicolumn{1}{c|}{0} & 
\backslash
multicolumn{1}{c|}{0} 
\backslash

\backslash
 
\backslash
cline{2-8}  
\end_layout

\begin_layout Plain Layout


\backslash
multicolumn{1}{c|}{} & 
\backslash
multicolumn{1}{c|}{O} & 
\backslash
multicolumn{1}{c|}{20} & 
\backslash
multicolumn{1}{c|}{2534} & 
\backslash
multicolumn{1}{c|}{0} & 
\backslash
multicolumn{1}{c|}{48} & 
\backslash
multicolumn{1}{c|}{21} & 
\backslash
multicolumn{1}{c|}{14} 
\backslash

\backslash
 
\backslash
cline{2-8}  
\end_layout

\begin_layout Plain Layout


\backslash
multicolumn{1}{c|}{} & 
\backslash
multicolumn{1}{c|}{U} & 
\backslash
multicolumn{1}{c|}{15} & 
\backslash
multicolumn{1}{c|}{97} & 
\backslash
multicolumn{1}{c|}{2913} & 
\backslash
multicolumn{1}{c|}{3} & 
\backslash
multicolumn{1}{c|}{11} & 
\backslash
multicolumn{1}{c|}{73} 
\backslash

\backslash
 
\backslash
cline{2-8}  
\end_layout

\begin_layout Plain Layout


\backslash
multicolumn{1}{c|}{} & 
\backslash
multicolumn{1}{c|}{D} & 
\backslash
multicolumn{1}{c|}{63} & 
\backslash
multicolumn{1}{c|}{9} & 
\backslash
multicolumn{1}{c|}{15} & 
\backslash
multicolumn{1}{c|}{3097} & 
\backslash
multicolumn{1}{c|}{181} & 
\backslash
multicolumn{1}{c|}{133} 
\backslash

\backslash
 
\backslash
cline{2-8}  
\end_layout

\begin_layout Plain Layout


\backslash
multicolumn{1}{c|}{} & 
\backslash
multicolumn{1}{c|}{R} & 
\backslash
multicolumn{1}{c|}{64} & 
\backslash
multicolumn{1}{c|}{24} & 
\backslash
multicolumn{1}{c|}{22} & 
\backslash
multicolumn{1}{c|}{13} & 
\backslash
multicolumn{1}{c|}{3447} & 
\backslash
multicolumn{1}{c|}{17} 
\backslash

\backslash
 
\backslash
cline{2-8}  
\end_layout

\begin_layout Plain Layout


\backslash
multicolumn{1}{c|}{} & 
\backslash
multicolumn{1}{c|}{L} & 
\backslash
multicolumn{1}{c|}{0} & 
\backslash
multicolumn{1}{c|}{1} & 
\backslash
multicolumn{1}{c|}{1} & 
\backslash
multicolumn{1}{c|}{23} & 
\backslash
multicolumn{1}{c|}{0} & 
\backslash
multicolumn{1}{c|}{2973} 
\backslash

\backslash
 
\backslash
cline{2-8}  
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular} 
\end_layout

\begin_layout Plain Layout


\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Section
Deconvolutional Neural Network
\end_layout

\begin_layout Standard
convolutional layer -> transpose
\end_layout

\begin_layout Standard
maxpooling->maxunpooling
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/unpooling.png
	lyxscale 50
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Maxpooling and max-unpooling
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\begin_inset Graphics
	filename images/deconv.png
	lyxscale 20
	scale 20

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Visualization of activations in our deconvolution network for 6 classes(first
 row: close, down, left; second row: open, right,up)
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Discussion
\end_layout

\begin_layout Standard
\begin_inset Quotes eld
\end_inset

Discuss how you would change your approach now that you have seen the other
 approaches and now that you know how well you did.
\begin_inset Quotes erd
\end_inset


\end_layout

\end_body
\end_document
